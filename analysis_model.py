import numpy as np
import math
from mediapipe import solutions
from mediapipe.framework.formats import landmark_pb2
import mediapipe as mp
from mediapipe.tasks import python
import cv2
import json
import os
import time

# GCS ä¸‹è¼‰å½±ç‰‡
import requests
import tempfile 

# Gemini API å¥—ä»¶
from google import genai
from google.genai import types


def pixel_distance(landmarker_list ,lm_1, lm_2, video_w, video_h):
    dx = (landmarker_list[lm_1].x - landmarker_list[lm_2].x) * video_w
    dy = (landmarker_list[lm_1].y - landmarker_list[lm_2].y) * video_h
    return math.sqrt(dx**2 + dy**2)

def angle_with_ground(landmarker_list, side = "right"):
    if side == "right":
        wrist, elbow = np.array([landmarker_list[16].x, landmarker_list[16].y]), np.array([landmarker_list[14].x, landmarker_list[14].y])
    else:
        wrist, elbow = np.array([landmarker_list[15].x, landmarker_list[15].y]), np.array([landmarker_list[13].x, landmarker_list[13].y])
    v_forearm = wrist - elbow
    v_vertical = np.array([0, -1])
    dot_product = np.dot(v_forearm, v_vertical)
    norm_forearm = np.linalg.norm(v_forearm)
    norm_vertical = np.linalg.norm(v_vertical)
    cos_theta = np.clip(dot_product / (norm_forearm * norm_vertical), -1.0, 1.0)
    angle_rad = np.arccos(cos_theta)
    angle_deg = np.degrees(angle_rad)
    return angle_deg

def draw_landmarks_on_image(rgb_image, detection_result):
    pose_landmarks_list = detection_result.pose_landmarks
    annotated_image = np.copy(rgb_image)
    image_height, image_width, _ = annotated_image.shape
    for idx in range(len(pose_landmarks_list)):
        pose_landmarks = pose_landmarks_list[idx]
        for i in range(11,33):
            if i in [17, 18, 19 ,20, 21, 22]:
                continue
            landmark = pose_landmarks[i] 
            pixel_x = int(landmark.x * image_width)
            pixel_y = int(landmark.y * image_height)
            text = f"X:{landmark.x:.2f} Y:{landmark.y:.2f} Z:{landmark.z:.2f}"
    pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()
    pose_landmarks_proto.landmark.extend([
      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in pose_landmarks
    ])
    solutions.drawing_utils.draw_landmarks(
      annotated_image,
      pose_landmarks_proto,
      solutions.pose.POSE_CONNECTIONS,
      solutions.drawing_styles.get_default_pose_landmarks_style())
    return annotated_image

def calculate_horizontal_abduction(landmarker_list, side='right'):
    if side == "right":
        left_shoulder, right_shoulder, elbow = np.array([landmarker_list[11].x, landmarker_list[11].z]), np.array(
            [landmarker_list[12].x, landmarker_list[12].z]), np.array([landmarker_list[14].x, landmarker_list[14].z])
        v_shoulder = left_shoulder - right_shoulder
        v_arm = elbow - right_shoulder
    elif side == "left":
        left_shoulder, right_shoulder, elbow = np.array([landmarker_list[11].x, landmarker_list[11].z]), np.array(
            [landmarker_list[12].x, landmarker_list[12].z]), np.array([landmarker_list[13].x, landmarker_list[13].z])
        v_shoulder = left_shoulder - right_shoulder
        v_arm = elbow - left_shoulder
    else:
        return print(f"This is not a correct parameter {side}")
    angle_shoulder = np.arctan2(v_shoulder[1], v_shoulder[0])
    angle_arm = np.arctan2(v_arm[1], v_arm[0])
    angle_diff_rad = angle_arm - angle_shoulder
    angle_diff_rad = (angle_diff_rad + np.pi) % (2 * np.pi) - np.pi
    angle_diff_deg = np.degrees(angle_diff_rad)
    if angle_diff_deg > 0: 
        final_angle_deg = 180 - angle_diff_deg
    else: 
        final_angle_deg = -(180 + angle_diff_deg)
    return final_angle_deg

def calculate_body_angle(landmarker_list, start_idx, center_idx, end_idx):
    start_point, center_point, end_point = np.array([landmarker_list[start_idx].x, landmarker_list[start_idx].y, landmarker_list[start_idx].z]), \
        np.array([landmarker_list[center_idx].x, landmarker_list[center_idx].y, landmarker_list[center_idx].z]), \
        np.array([landmarker_list[end_idx].x, landmarker_list[end_idx].y, landmarker_list[end_idx].z])
    v_a = start_point - center_point
    v_b = end_point - center_point
    dp = np.dot(v_a, v_b)
    mag = np.linalg.norm(v_a) * np.linalg.norm(v_b)
    cosine_angle = dp / mag
    cosine_angle = np.clip(cosine_angle, -1.0, 1.0)
    angle = np.degrees(np.arccos(cosine_angle))
    return angle


def format_timestamp(frame_number, fps):
    if fps <= 0: return "00:00"
    seconds = frame_number / fps
    m, s = divmod(seconds, 60)
    # å›å‚³ "00:05.33" æ ¼å¼ (åˆ†:ç§’.æ¯«ç§’)
    return f"{int(m):02d}:{s:05.2f}"

def convert2Json(peak_leg_tuple, foot_plant_tuple, maxER_tuple, ball_release_tuple,
           left_elbow_angle,right_elbow_angle,left_knee_angle,right_knee_angle,
           right_shoulder_abduction,left_shoulder_abduction,horizontal_abduction, 
           fps): 
    
    peak_leg = {
        "Frame": peak_leg_tuple[0],
        "Time": format_timestamp(peak_leg_tuple[0], fps)       
    }
    foot_plant = {
        "Frame": foot_plant_tuple[0],
        "Time": format_timestamp(foot_plant_tuple[0], fps),    
        "stride_percentage": foot_plant_tuple[1]
    }
    max_ER = {
        "Frame": maxER_tuple[0],
        "Time": format_timestamp(maxER_tuple[0], fps),         
        "ER(External Rotation)angle": maxER_tuple[1]
    }
    ball_release = {
        "Frame": ball_release_tuple[0],
        "Time": format_timestamp(ball_release_tuple[0], fps)   
    }

    keyframe = {
        "peak leg frame": peak_leg,
        "foot plant frame": foot_plant,
        "max ER frame": max_ER,
        "ball release frame": ball_release
    }
    frame_landmark = {
        "left_elbow_angle": left_elbow_angle,
        "right_elbow_angle": right_elbow_angle,
        "left_knee_angle": left_knee_angle,
        "right_knee_angle": right_knee_angle,
        "right_shoulder_abduction": right_shoulder_abduction,
        "left_shoulder_abduction": left_shoulder_abduction,
        "horizontal_abduction": horizontal_abduction,
        "keyframe": keyframe,
    }
    
    # ç§»é™¤ local file write
    # output_json_path = "json/Pitcher_pose_data.json"
    # with open(output_json_path, 'w', encoding='utf-8') as f:
    #     json.dump(frame_landmark, f, indent=4)
    # print(f"æˆåŠŸå°‡å§¿å‹¢æ•¸æ“šå„²å­˜è‡³: {output_json_path}")
    
    # å›å‚³ Python å­—å…¸
    return frame_landmark


# å°‡æ¨¡å‹è·¯å¾‘æ”¹ç‚ºã€Œç›¸å°è·¯å¾‘ã€
model_full_path = 'models/pose_landmarker_full.task'
model_heavy_path = 'models/pose_landmarker_heavy.task'
model_lite_path = "models/pose_landmarker_lite.task"

# å°‡ã€Œè¦å‰‡ã€ç§»åˆ°å‡½å¼å¤–éƒ¨ï¼Œä½œç‚ºå…¨åŸŸå¸¸æ•¸
RULES_PROMPT = '''
æ³¨æ„!!!åµæ¸¬å‡ºä¾†å¯èƒ½æœƒæœ‰æ­£è² 10åº¦çš„èª¤å·®!!!
================================================================================================================
ç¬¬ä¸€æ™‚æœŸï¼šé å‚™æœŸ (Wind-up)
ç›®æ¨™ï¼šå»ºç«‹ç©©å®šå¹³è¡¡çš„èµ·å§‹å‹•ä½œã€‚
è¦å‰‡ 1.1 - [é‡å¿ƒç©©å®š]ï¼š
    IF èº«é«”é‡å¿ƒï¼ˆéª¨ç›†ä¸­å¿ƒé»ï¼‰åœ¨æŠ¬è…¿éç¨‹ä¸­ï¼Œæ°´å¹³ä½ç§»éå¤§ï¼ŒTHEN æç¤ºã€Œèµ·å§‹å¹³è¡¡ä¸ä½³ï¼Œæ™ƒå‹•éå¤šå¯èƒ½å°è‡´åŠ›é‡æµå¤±ã€ã€‚
è¦å‰‡ 1.2 - [è»¸å¿ƒè…³æ”¯æ’è§’åº¦]ï¼š
    IF è»¸å¿ƒè…³ï¼ˆex:å·¦æŠ•æ˜¯å·¦è…³ï¼Œåä¹‹ï¼‰çš„è†è“‹è§’åº¦å¤§æ–¼ 160åº¦ï¼ˆéæ–¼ä¼¸ç›´ï¼‰æˆ–å°æ–¼ 120åº¦ï¼ˆéæ–¼å½æ›²ï¼‰ï¼ŒTHEN æç¤ºã€Œè»¸å¿ƒè…³è†è“‹è§’åº¦ä¸ä½³ï¼Œä¸åˆ©æ–¼å¾ŒçºŒåŠ›é‡çš„å„²å­˜èˆ‡çˆ†ç™¼ã€ã€‚
é¸æ“‡ä¾æ“šï¼š
è¦å‰‡ 1.1ï¼š
    é¸æ“‡ç›£æ¸¬é‡å¿ƒï¼Œæ˜¯å› ç‚ºã€Œå¹³è¡¡æ˜¯å‹•åŠ›éˆçš„èµ·é»ã€ã€‚
    å¦‚æœåœ¨ç¬¬ä¸€æ­¥å°±å¤±å»å¹³è¡¡ï¼Œå¾ŒçºŒæ‰€æœ‰éšæ®µçš„ç™¼åŠ›éƒ½æœƒè¢«è¿«ç”¨ä¾†ã€Œä¿®æ­£ã€è€Œéã€ŒåŠ é€Ÿã€ï¼Œå°è‡´åŠ›é‡å‚³éä¸­æ–·ã€‚
è¦å‰‡ 1.2ï¼š
    é¸æ“‡æª¢æŸ¥è»¸å¿ƒè…³è†è“‹ï¼Œæ˜¯å› ç‚ºæ­¤ç‚ºç™¼åŠ›çš„ã€Œèµ·é»ã€ã€‚è†è“‹éåº¦ä¼¸ç›´(å¤§æ–¼170åº¦)æœƒä½¿è…¿éƒ¨è‚Œè‚‰åƒµç¡¬ï¼Œç„¡æ³•ç”¢ç”Ÿå½ˆæ€§èˆ‡çˆ†ç™¼åŠ›ï¼›
    éåº¦å½æ›²(å°æ–¼110åº¦)å‰‡æœƒè®“é‡å¿ƒéä½ã€å§¿å‹¢ä¸ç©©ã€‚æ­¤è¦å‰‡ç¢ºä¿æŠ•æ‰‹è™•æ–¼ä¸€å€‹ã€Œéš¨æ™‚å¯ç™¼åŠ›ã€çš„é‹å‹•æº–å‚™ç‹€æ…‹ã€‚
    è€Œæ•¸æ“š(150åº¦~120åº¦)æ˜¯å› ç‚ºæ ¹æ“šè«–æ–‡æ‰€èªªè»¸å¿ƒè…³å¾®å½ï¼ŒåŠ ä¸Šæ•¸æ“šç«¯çš„èª¤å·®æ‰€è¨­å®šçš„ã€‚
================================================================================================================
ç¬¬äºŒæ™‚æœŸï¼šè·¨æ­¥æœŸ(Stride)
ç›®æ¨™ï¼šç·šæ€§åœ°å°‡åŠ›é‡å¼•å°è‡³æœ¬å£˜æ¿ã€‚
è¦å‰‡ 2.1 - [è·¨æ­¥è·é›¢]ï¼š
    IFå‰è…³è½åœ°æ™‚ï¼Œé›™è…³è¸ä¹‹é–“ç‚ºèº«é«˜çš„75%(èª¤å·®ç‚ºæ­£è² 5%)ï¼ŒTHEN æç¤ºã€Œè·¨æ­¥è·é›¢å¯èƒ½éçŸ­/éé•·ï¼Œå½±éŸ¿å‹•åŠ›éˆçš„é †æš¢åº¦ã€ã€‚
è¦å‰‡ 2.2 - [è½åœ°è…³ç©©å®šæ€§]ï¼š
    IFå‰è…³è½åœ°ç¬é–“ï¼Œè†è“‹è§’åº¦å°æ–¼150åº¦(éåº¦å½æ›²)æˆ–å¤§æ–¼ 120åº¦(æ¥è¿‘ä¼¸ç›´ï¼‰ï¼ŒTHENæç¤ºã€Œå‰è…³è½åœ°æ™‚è†è“‹è§’åº¦éæ–¼ä¼¸ç›´æˆ–æ˜¯å½æ›²å°è‡´ä¸ç©©ï¼Œå¯èƒ½é€ æˆåŠ›é‡ä¸­æ–·æˆ–å¢åŠ è†é—œç¯€å£“åŠ›ã€ã€‚
è¦å‰‡ 2.3 - [æŠ•çƒè‡‚è‚©å¤–å±•]ï¼š  
    IFè‚©å¤–å±•è§’åº¦å°æ–¼80åº¦å¤§æ–¼100åº¦ï¼ŒTHENæç¤ºã€Œè‚©éœ€è¦å¤¾ä¸€é»æˆ–é–‹ä¸€é»ã€ã€‚
é¸æ“‡ä¾æ“š:
è¦å‰‡ 2.1:
    è·¨æ­¥é•·åº¦ä¹‹æ‰€ä»¥éœ€è¦é”åˆ°é€™å€‹ç‰¹å®šçš„æ¯”ä¾‹ï¼Œæ˜¯ç‚ºäº†ç¢ºä¿æŠ•çƒå‹•ä½œä¸­é—œéµçš„ç”Ÿç‰©åŠ›å­¸ã€æ™‚é–“å”èª¿å’Œèƒ½é‡å‚³éèƒ½é”åˆ°æœ€ä½³ç‹€æ…‹ï¼ŒåŒæ™‚é™ä½å—å‚·é¢¨éšªã€‚æ­£ç¢ºçš„è·¨æ­¥é•·åº¦ä¹Ÿå°æ–¼å»ºç«‹ç©©å®šçš„æŠ•çƒåŸºç¤å¾ˆé‡è¦ã€‚
è¦å‰‡ 2.2:
    è§’è½åœ°æ™‚ï¼Œå‰è†è“‹å½æ›²ä¾†å¸æ”¶è‘—åœ°æ™‚çš„è¡æ“ŠåŠ›ï¼Œä»¥ä¿è­·è†è“‹å…å—å‚·å®³ã€‚ä¹Ÿèƒ½å¸¶ä¾†ä¸€å®šçš„é‡å¿ƒç©©åœ°åº¦ã€‚
è¦å‰‡ 2.3:
    ç‚ºäº†ç¢ºä¿æŠ•æ‰‹æœ‰æ­£ç¢ºæ‰‹éƒ¨æ“ºæ”¾ä½ç½®ï¼Œä»¥é˜²æ­¢æŠ•æ‰‹æ‰‹éƒ¨è² æ“”ã€‚
    å‡å¦‚è‚©è†€æ°´å¹³å¤–å±•éå¤šï¼Œå¯èƒ½å°è‡´è‚©é—œç¯€å›ŠéŸŒå¸¶æ’•è£‚ã€‚
================================================================================================================
ç¬¬ä¸‰æ™‚æœŸï¼šä¸Šè‡‚èˆ‰çƒæœŸ (Arm Cocking)
ç›®æ¨™ï¼šæœ€å¤§åŒ–èº«é«”çš„æ‰­è½‰èˆ‡å½ˆæ€§èƒ½é‡å„²å­˜ï¼ˆçƒé€Ÿçš„é—œéµï¼‰ã€‚
è¦å‰‡ 3.1 - [æ‰‹è‡‚ä½ç½®]ï¼š
    IF æŠ•çƒæ‰‹è‡‚çš„è‚©è†€å¤–å±•è§’åº¦é å°æ–¼ 85åº¦ æˆ–å¤§æ–¼ 110åº¦ï¼ŒTHENæç¤ºã€Œæ‰‹è‡‚èˆ‡èº«é«”çš„å¤¾è§’ä¸ç•¶ï¼Œå¯èƒ½å°è‡´ã€æ‰‹è‡‚æ‹–æ›³ (Arm Drag)ã€ï¼Œå¢åŠ è‚©è†€å—å‚·é¢¨éšªã€ã€‚
è¦å‰‡ 3.2 - [è‚©å¤–æ—‹è§’åº¦]ï¼š
    IF æŠ•çƒå´çš„è‚©è†€æœ€å¤§å¤–æ—‹(Max ER)è§’åº¦æ˜é¡¯ä¸è¶³ï¼ˆå°æ–¼ 160åº¦ï¼‰ï¼ŒTHENæç¤ºã€Œæ‰‹è‡‚å‘å¾Œä¼¸å±•å¹…åº¦ä¸è¶³ï¼Œå½±éŸ¿åŠ›é‡çš„å®Œå…¨å„²å­˜ã€ã€‚
é¸æ“‡ä¾æ“š:
è¦å‰‡ 3.1:
    æ ¹æ“šè«–æ–‡ç ”ç©¶é¡¯ç¤ºè‚©å¤–å±•åœ¨90åº¦æœƒæœ‰æœ€å¤§çš„æ´»å‹•ç¯„åœ
è¦å‰‡ 3.2:
    æƒ³åƒæ‰‹è‡‚ç‚ºæ©¡çš®ç­‹ï¼Œè¢«æ‹‰å‡åˆ°æœ€é•·ï¼Œä¸¦é‡‹æ”¾çš„éç¨‹ï¼Œå‡å¦‚å¤–æ—‹ä¸è¶³æœƒå°è‡´è‚©è†€å…§æ—‹é€Ÿåº¦ä½ï¼Œé€²è€Œå°è‡´çƒé€Ÿä½ã€‚
================================================================================================================
ç¬¬å››æ™‚æœŸï¼šä¸Šè‡‚åŠ é€ŸæœŸ (Arm Acceleration)
ç›®æ¨™ï¼šå°‡å„²å­˜çš„èƒ½é‡ä¾åºã€é«˜æ•ˆåœ°é‡‹æ”¾ã€‚
è¦å‰‡ 4.1 - [å‰è…³æ”¯æ’]ï¼š
    IFåœ¨çƒé›¢æ‰‹ç¬é–“ï¼Œå‰è…³è†è“‹è§’åº¦ä»å°æ–¼140åº¦ï¼ˆå½æ›²éå¤šï¼‰ï¼ŒTHENæç¤ºã€Œå‰è…³æ”¯æ’è…¿éè»Ÿï¼Œæœªèƒ½å½¢æˆç©©å›ºçš„æ”¯é»ï¼Œé€ æˆåŠ›é‡æµå¤±ã€ã€‚
è¦å‰‡ 4.2 - [å‡ºæ‰‹æ™‚çš„æ‰‹è‡‚è§’åº¦]ï¼š
    IFåœ¨çƒé›¢æ‰‹ç¬é–“ï¼Œæ‰‹è‚˜å½æ›²è§’åº¦å°æ–¼135åº¦ï¼ŒTHENæç¤ºã€Œå‡ºæ‰‹æ™‚æ‰‹è‡‚ä¼¸å±•ä¸å®Œå…¨ï¼ŒåŠ›é‡æœªå®Œå…¨é‡‹æ”¾ï¼Œå‹•ä½œæ›´åƒæ˜¯ã€æ¨çƒã€è€Œéã€ç”©é­ã€ã€ã€‚
è¦å‰‡ 4.3 - [èº«é«”å‰å‚¾]ï¼š
    IFåœ¨çƒé›¢æ‰‹ç¬é–“ï¼Œèº«é«”è»€å¹¹å‰å‚¾è§’åº¦ä¸è¶³ï¼ˆå°æ–¼ 35åº¦ï¼‰ï¼ŒTHENæç¤ºã€Œå‡ºæ‰‹æ™‚èº«é«”è·Ÿé€²ä¸è¶³ï¼Œæœªèƒ½æœ‰æ•ˆåˆ©ç”¨å…¨èº«çš„é«”é‡å»åŠ é€Ÿã€ã€‚
é¸æ“‡ä¾æ“š:
è¦å‰‡ 4.1:
    å‰å°è†çš„ã€Œé–å®šã€ä½œç”¨ï¼Œå®ƒä½œç‚ºä¸€å€‹ç©©å›ºçš„æ”¯é»ï¼Œå°‡ä¸‹åŠèº«çš„å‹•èƒ½å‚³éåˆ°è»€å¹¹å’Œæ‰‹è‡‚ã€‚
è¦å‰‡ 4.2:
    è¦è®“æ‰‹è‚˜ä¸¦éå®Œå…¨ä¼¸ç›´ï¼Œä»ä¿ç•™è¼•å¾®å½æ›²ã€‚é‚„æœƒä¿ç•™ä¸€é»å½ˆæ€§ï¼Œé¿å…æ‰‹è‚˜ä¼¸ç›´è€Œé–æ­»å—å‚·ã€‚
è¦å‰‡ 4.3:
    è»€å¹¹åœ¨é‡‹æ”¾çƒæ™‚çš„ç²¾ç¢ºå‚¾æ–œè§’åº¦ï¼Œé€™æœ‰åŠ©æ–¼æœ€å¤§åŒ–èƒ½é‡å‚³éå’Œç©©å®šæ€§ã€‚
================================================================================================================
ç¬¬äº”æ™‚æœŸ / ç¬¬å…­æ™‚æœŸï¼šæ¸›é€ŸæœŸ (Deceleration / Fallow Through)
ç›®æ¨™ï¼šå®‰å…¨åœ°å¸æ”¶å·¨å¤§çš„æ‰‹è‡‚å‹•èƒ½ï¼Œé¿å…å—å‚·ã€‚
è¦å‰‡ 5.1 - [æ‰‹è‡‚é †å‹¢å‹•ä½œ]ï¼š
    IF æ‰‹è‡‚åœ¨çƒé›¢æ‰‹å¾Œï¼Œæ²’æœ‰é †å‹¢åŠƒéèº«é«”åˆ°å°å´è†è“‹é™„è¿‘ï¼Œè€Œæ˜¯éæ—©åœæ­¢ï¼ŒTHEN æç¤ºã€Œæ¸›é€Ÿä¸å®Œå…¨ï¼é€™æœƒè®“è‚©è†€èˆ‡æ‰‹è‚˜æ‰¿å—å·¨å¤§çš„è¡æ“ŠåŠ›ï¼Œæ˜¯å—å‚·çš„é«˜é¢¨éšªå‹•ä½œã€ã€‚
è¦å‰‡ 5.2 - [èº«é«”å”åŠ©æ¸›é€Ÿ]ï¼š
    IF åœ¨æ­¤éšæ®µï¼Œèº«é«”è»€å¹¹çš„æœ€å¤§å‰å‚¾è§’åº¦ä¸è¶³ï¼ˆå°æ–¼ 40åº¦ï¼‰ï¼ŒTHEN æç¤ºã€Œèº«é«”æ²’æœ‰å……åˆ†å‰å‚¾ä¾†å¹«åŠ©å¸æ”¶æ‰‹è‡‚çš„æ¸›é€ŸåŠ›é‡ï¼Œå£“åŠ›éåº¦é›†ä¸­åœ¨æ‰‹è‡‚ä¸Šã€ã€‚
'''

def get_gemini_report_from_video(video_gcs_url, side, gemini_api_key):
    """
    é€™æ˜¯ app.py æœƒå‘¼å«çš„ã€Œä¸»è¦å‡½å¼ã€ã€‚
    å®ƒè² è²¬ä¸²è¯æ•´å€‹ AI æµç¨‹ï¼š
    1. å¾ GCS ä¸‹è¼‰å½±ç‰‡åˆ°æš«å­˜æª”
    2. åŸ·è¡Œ MediaPipe åˆ†æ
    3. ç”¢ç”ŸåŸå§‹ JSON (in memory)
    4. ä¸Šå‚³å½±ç‰‡åˆ° Gemini
    5. å‘¼å« Gemini API (å«å½±ç‰‡ + JSON)
    6. å›å‚³ Gemini ç”Ÿæˆçš„ Markdown æ–‡å­—
    """
    
    local_temp_video_path = None
    try:
        # -------------------------------------------------
        # æ­¥é©Ÿ 1: å¾ GCS URL ä¸‹è¼‰å½±ç‰‡åˆ°æš«å­˜æª”
        # -------------------------------------------------
        print(f"[AI æµç¨‹]ï¼šé–‹å§‹å¾ GCS ä¸‹è¼‰ {video_gcs_url}")
        # å»ºç«‹ä¸€å€‹æš«å­˜æª”æ¡ˆ (å½±ç‰‡)
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as temp_file:
            local_temp_video_path = temp_file.name
            # ä½¿ç”¨ requests ä¸‹è¼‰
            with requests.get(video_gcs_url, stream=True) as r:
                r.raise_for_status()
                for chunk in r.iter_content(chunk_size=8192): 
                    temp_file.write(chunk)
        
        print(f"[AI æµç¨‹]ï¼šå½±ç‰‡å·²ä¸‹è¼‰åˆ°æš«å­˜è·¯å¾‘: {local_temp_video_path}")
        
        # -------------------------------------------------
        # æ­¥é©Ÿ 2: åŸ·è¡Œ Gemini Client å’Œ MediaPipe
        # -------------------------------------------------
        
        # ç§»é™¤ input()ï¼Œä½¿ç”¨å‡½å¼åƒæ•¸
        video = local_temp_video_path
        # side = input("è«‹è¼¸å…¥æ˜¯å·¦æŠ•é‚„æ˜¯å³æŠ•(left or right) : ") # -> å·²ç”±åƒæ•¸ 'side' å‚³å…¥

        # ä½¿ç”¨å‚³å…¥çš„ API Key
        client = genai.Client(api_key=gemini_api_key)
        chat = client.chats.create(model="gemini-3-pro-preview", config=types.GenerateContentConfig(
            system_instruction = f"""
            ä½ æ˜¯ä¸€ä½ MLB é ‚ç´šçš„æŠ•æ‰‹é‹å‹•ç§‘å­¸å°ˆå®¶ã€‚è«‹æ ¹æ“šæä¾›çš„å½±ç‰‡å’Œ JSON æ•¸æ“šé€²è¡Œåˆ†æã€‚

            ã€é‡è¦ï¼šè¼¸å‡ºæ ¼å¼è¦æ±‚ã€‘
            1. è«‹å‹™å¿…ä½¿ç”¨ **Markdown** æ ¼å¼è¼¸å‡ºï¼Œä»¥ä¾¿åœ¨ç¶²é ä¸Šæ¼‚äº®åœ°é¡¯ç¤ºã€‚
            2. è«‹ä½¿ç”¨ **H2 (##)** æ¨™é¡Œä¾†å€åˆ†æ¯å€‹æ™‚æœŸ (ä¾‹å¦‚ï¼š## ç¬¬ä¸€æ™‚æœŸï¼šé å‚™æœŸ)ã€‚
            3. è«‹ä½¿ç”¨ **H3 (###)** æ¨™é¡Œä¾†å€åˆ†æ¯å€‹è¦å‰‡ (ä¾‹å¦‚ï¼š### 1.1 æŠ¬è…¿é«˜åº¦)ã€‚
            4. åœ¨æåˆ°é—œéµå‹•ä½œæ™‚ï¼Œè«‹å‹™å¿…æ¨™è¨» **æ™‚é–“é»** (ä¾‹å¦‚ï¼š**åœ¨ 00:02.45 æ™‚**)ï¼Œè€Œä¸åªæ˜¯å¹€æ•¸ã€‚æ•¸æ“šä¸­å·²æœ‰ "Time" æ¬„ä½ã€‚
            5. ä½¿ç”¨ **åˆ—è¡¨ (-)** å’Œ **ç²—é«” (**...**)** ä¾†å¼·èª¿é‡é»ã€‚
            6. å°æ–¼æ¯å€‹è¦å‰‡ï¼Œè«‹åŒ…å«ï¼š
               - **æ¨™æº–ï¼š** ...
               - **ä½ çš„è¡¨ç¾ï¼š** (é™„ä¸Šæ™‚é–“é») ...
               - **è©•åˆ†ï¼š** (åˆæ ¼/ä¸åˆæ ¼ï¼Œè«‹ç”¨ç²—é«”)
               - **å°ˆå®¶å»ºè­°ï¼š** ...

            ä»¥ä¸‹æ˜¯è©³ç´°çš„åˆ†æè¦å‰‡ï¼š
            {RULES_PROMPT}
            """)
            )
        
        print("[AI æµç¨‹]ï¼šé–‹å§‹ä¸Šå‚³å½±ç‰‡åˆ° Gemini...")
        gvideo = client.files.upload(file = video)
        
        print(f"Gemini Video is {gvideo.state.name}")
        while gvideo.state.name == "PROCESSING":
            print("still processing...")
            time.sleep(5)
            gvideo = client.files.get(name=gvideo.name)
        print(f"[AI æµç¨‹]ï¼šGemini å½±ç‰‡ä¸Šå‚³å®Œæˆ {gvideo.state.name}")

        # å½±ç‰‡ mediapipeè¨­å®š
        BaseOptions = mp.tasks.BaseOptions
        PoseLandmarker = mp.tasks.vision.PoseLandmarker
        PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions
        VisionRunningMode = mp.tasks.vision.RunningMode

        options = PoseLandmarkerOptions(
            base_options=BaseOptions(model_asset_path=model_full_path),
            running_mode=VisionRunningMode.VIDEO,
            min_pose_detection_confidence=0.6,
            min_pose_presence_confidence=0.6,
            min_tracking_confidence=0.6)

        # -------------------------------------------------
        # æ­¥é©Ÿ 3: MediaPipe è™•ç†è¿´åœˆ
        # -------------------------------------------------
        print(f"[AI æµç¨‹]ï¼šé–‹å§‹ MediaPipe é€å¹€åˆ†æ...")
        timestamp_ms = 0
        with PoseLandmarker.create_from_options(options) as landmarker1:
            cap1 = cv2.VideoCapture(video_gcs_url)
            fps = cap1.get(cv2.CAP_PROP_FPS)

            frame_index = 0
            temp_frame = []
            temp_angle = []
            knee_heights = []
            ankle_distances = []
            wrist_vs_head = []
            left_elbow_angle = []
            right_elbow_angle = []
            left_knee_angle = []
            right_knee_angle = []
            left_shoulder_abduction = []
            right_shoulder_abduction = []
            horizontal_abduction = []

            while cap1.isOpened():
                success1, frame1 = cap1.read()
                if not success1:
                    break
                frame_index += 1

                mp_image1 = mp.Image(image_format=mp.ImageFormat.SRGB, data=cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB))
                timestamp_ms = int(frame_index * 1000 / fps)
                
                pose_landmarker_result1 = landmarker1.detect_for_video(mp_image1, timestamp_ms)
                
                # è™•ç† MediaPipe æ‰¾ä¸åˆ°å§¿å‹¢çš„ç‹€æ³
                if not pose_landmarker_result1.pose_landmarks:
                    print(f"Frame {frame_index}: No pose detected, skipping.")
                    continue
                
                landmarker_list1 = pose_landmarker_result1.pose_landmarks[0]

                if frame_index == 1:
                    h, w, _ = frame1.shape
                    body_h = pixel_distance(landmarker_list1, lm_1=0, lm_2=30, video_h=h, video_w=w)
                
                if side == "right":
                    knee_y = landmarker_list1[25].y
                    hip_y = landmarker_list1[23].y
                    knee_heights.append((frame_index, hip_y - knee_y))
                    wrist = landmarker_list1[16]
                    head = landmarker_list1[0]
                    if wrist.x >= head.x:
                        wrist_vs_head.append((frame_index, wrist.y - head.y))
                    if landmarker_list1[11].y > landmarker_list1[12].y and landmarker_list1[14].y < landmarker_list1[12].y and \
                            landmarker_list1[16].y < landmarker_list1[14].y:
                        temp_frame.append(frame_index)
                        temp_angle.append(angle_with_ground(landmarker_list1, side))
                else:
                    knee_y = landmarker_list1[26].y
                    hip_y = landmarker_list1[24].y
                    knee_heights.append((frame_index, hip_y - knee_y))
                    wrist = landmarker_list1[15]
                    head = landmarker_list1[0]
                    if wrist.x <= head.x:
                        wrist_vs_head.append((frame_index, wrist.y - head.y))
                    if landmarker_list1[11].y < landmarker_list1[12].y and landmarker_list1[13].y < landmarker_list1[12].y and \
                            landmarker_list1[15].y < landmarker_list1[13].y:
                        temp_frame.append(frame_index)
                        temp_angle.append(angle_with_ground(landmarker_list1, side))

                foot_dist = pixel_distance(landmarker_list1, lm_1=27, lm_2=28, video_h=h, video_w=w)
                ratio = (foot_dist / (body_h + 155)) * 100
                ankle_distances.append((frame_index, ratio))
                
                left_elbow_angle.append({"frame": frame_index, "angle": calculate_body_angle(landmarker_list1, 15, 13, 11)})
                right_elbow_angle.append({"frame": frame_index, "angle": calculate_body_angle(landmarker_list1, 16, 14, 12)})
                left_knee_angle.append({"frame": frame_index, "angle": calculate_body_angle(landmarker_list1, 23, 25, 27)})
                right_knee_angle.append({"frame": frame_index, "angle": calculate_body_angle(landmarker_list1, 24, 26, 28)})
                horizontal_abduction.append({"frame": frame_index, "angle": calculate_horizontal_abduction(landmarker_list1, side)})
                right_shoulder_abduction.append({"frame": frame_index, "angle": calculate_body_angle(landmarker_list1, 14, 12, 24)})
                left_shoulder_abduction.append({"frame": frame_index, "angle": calculate_body_angle(landmarker_list1, 13, 11, 23)})


            print(f"[AI æµç¨‹]ï¼šMediaPipe é€å¹€åˆ†æå®Œæˆã€‚")
            print("\n" + "="*30)
            print("ğŸ¤– [AI æµç¨‹]ï¼šé–‹å§‹é™¤éŒ¯ (Debug) é—œéµå¹€åˆ—è¡¨...")
            print(f"DEBUG: 'temp_frame' (Max ER å€™é¸): {temp_frame}")
            print(f"DEBUG: 'temp_angle' (Max ER å€™é¸è§’åº¦): {temp_angle}")
            print(f"DEBUG: 'wrist_vs_head' (Ball Release å€™é¸): {wrist_vs_head}")
            print(f"DEBUG: 'knee_heights' (Peak Leg å€™é¸): {knee_heights}")
            print(f"DEBUG: 'ankle_distances' (Foot Plant å€™é¸): {ankle_distances}")
            print("="*30 + "\n")
            # -------------------------------------------------
            # æ­¥é©Ÿ 4: é—œéµå¹€æå– (ä¾†è‡ªæ‚¨çš„ main.py)
            # -------------------------------------------------

            # æª¢æŸ¥ Ball release
            if not wrist_vs_head:
                raise ValueError("MediaPipe è™•ç†å¤±æ•—ï¼š'wrist_vs_head' åˆ—è¡¨ç‚ºç©ºï¼Œç„¡æ³•åµæ¸¬åˆ°å‡ºæ‰‹é»ã€‚å½±ç‰‡å¯èƒ½å¤ªçŸ­æˆ–ç„¡æ³•è¾¨è­˜ã€‚")
            ball_release_tuple = min(wrist_vs_head, key=lambda x: x[1])
            print(f"é—œéµå¹€ Ball release: {ball_release_tuple[0]}")

            # æª¢æŸ¥ Peak Leg
            search_window_pl = [x for x in knee_heights if x[0] < ball_release_tuple[0]]
            if not search_window_pl:
                raise ValueError("MediaPipe è™•ç†å¤±æ•—ï¼š'search_window_pl' åˆ—è¡¨ç‚ºç©ºï¼Œç„¡æ³•åµæ¸¬åˆ°æŠ¬è…¿é«˜å³°ã€‚")
            peak_leg_tuple = max(search_window_pl, key=lambda x: x[1])
            print(f"é—œéµå¹€ Peak Leg: {peak_leg_tuple[0]}")

            # æª¢æŸ¥ Foot plant
            search_window_fp = [x for x in ankle_distances if x[0] > peak_leg_tuple[0] and x[0] < ball_release_tuple[0]]
            if not search_window_fp:
                raise ValueError("MediaPipe è™•ç†å¤±æ•—ï¼š'search_window_fp' åˆ—è¡¨ç‚ºç©ºï¼Œç„¡æ³•åµæ¸¬åˆ°è·¨æ­¥è½åœ°ã€‚")
            foot_plant_tuple = max(search_window_fp, key=lambda x: x[1])
            print(f"é—œéµå¹€ Foot plant: {foot_plant_tuple[0]}")

            # æª¢æŸ¥ Max ER
            frame_stride2BallRelease = [i for i in temp_frame if foot_plant_tuple[0]<i<ball_release_tuple[0]]
            if not frame_stride2BallRelease:
                 raise ValueError("MediaPipe è™•ç†å¤±æ•—ï¼š'frame_stride2BallRelease' åˆ—è¡¨ç‚ºç©ºï¼Œç„¡æ³•åµ"
                                  "æ¸¬åˆ°æœ€å¤§å¤–æ—‹å€é–“ã€‚")
            
            index_frame =[temp_frame.index(i) for i in frame_stride2BallRelease]
            parallel = [np.abs(temp_angle[i]).tolist() for i in index_frame]
            near_parallel_num = [np.abs(temp_angle[i]-90).tolist() for i in index_frame]
            
            if not near_parallel_num:
                raise ValueError("MediaPipe è™•ç†å¤±æ•—ï¼š'near_parallel_num' åˆ—è¡¨ç‚ºç©ºï¼Œç„¡æ³•è¨ˆç®—æœ€å¤§å¤–æ—‹ã€‚")
                
            idx = near_parallel_num.index(min(near_parallel_num))
            maxER_tuple = (frame_stride2BallRelease[idx], parallel[idx]+90)
            print(f"é—œéµå¹€ Max ER: {maxER_tuple[0]}")

            print(f"[AI æµç¨‹]ï¼šé—œéµå¹€æå–å®Œæˆã€‚")

            # -------------------------------------------------
            # æ­¥é©Ÿ 5: ç”¢ç”Ÿ JSON (in memory)
            # -------------------------------------------------
            # å‘¼å«ä¿®æ”¹å¾Œçš„ convert2Jsonï¼Œå®ƒæœƒå›å‚³ dict
            json_dict = convert2Json(peak_leg_tuple, foot_plant_tuple, maxER_tuple, ball_release_tuple,
                       left_elbow_angle,right_elbow_angle,left_knee_angle,right_knee_angle,
                       right_shoulder_abduction,left_shoulder_abduction,horizontal_abduction,fps)
            
            # ç›´æ¥å¾ dict è½‰æ›ç‚º stringï¼Œä¸å†è®€å–æœ¬åœ°æª”æ¡ˆ
            json_data_as_string = json.dumps(json_dict, indent=2, ensure_ascii=False)

            # -------------------------------------------------
            # æ­¥é©Ÿ 6: å‘¼å« Gemini API
            # -------------------------------------------------
            print(f"[AI æµç¨‹]ï¼šæ­£åœ¨ç™¼é€æœ€çµ‚æç¤º (Prompt) åˆ° Gemini...")
            
            # ===== é‡è©¦é‚è¼¯ =====
            max_retries = 5  # æœ€å¤šé‡è©¦ 5 æ¬¡
            retry_count = 0
            final_response_text = None
            
            while retry_count < max_retries:
                try:
                    # å˜—è©¦ç™¼é€è«‹æ±‚
                    response = chat.send_message([gvideo, f"é€™æ˜¯ä¸€ä½{side}æŠ•æ‰‹ï¼Œä»¥ä¸‹æ˜¯æˆ‘çµ¦ä½ çš„å½±ç‰‡è·Ÿjsonæª”éšæ®µçš„è³‡è¨Š : {json_data_as_string}ï¼Œæˆ‘å°‡é—œéµå¹€éƒ½æ”¾åœ¨keyframeè£¡äº†"])
                    
                    # å¦‚æœæˆåŠŸï¼Œå°±å­˜ä¸‹çµæœä¸¦è·³å‡ºè¿´åœˆ
                    final_response_text = response.text
                    print(f"[AI æµç¨‹]ï¼šGemini å›æ‡‰å·²æ”¶åˆ°ï¼")
                    break 
                    
                except Exception as e:
                    # æª¢æŸ¥æ˜¯å¦ç‚º 503 (Overloaded) æˆ– 429 (Rate Limit) éŒ¯èª¤
                    error_str = str(e)
                    if "503" in error_str or "429" in error_str or "Overloaded" in error_str:
                        retry_count += 1
                        wait_time = 2 ** retry_count # æŒ‡æ•¸é€€é¿: ç­‰å¾… 2, 4, 8, 16, 32 ç§’
                        print(f"[AI æµç¨‹]ï¼šGemini ä¼ºæœå™¨å¿™ç¢Œ (503/429)ï¼Œæ­£åœ¨ç­‰å¾… {wait_time} ç§’å¾Œé‡è©¦ ({retry_count}/{max_retries})...")
                        time.sleep(wait_time)
                    else:
                        # å¦‚æœæ˜¯å…¶ä»–éŒ¯èª¤ (ä¾‹å¦‚ç¨‹å¼ç¢¼å¯«éŒ¯)ï¼Œå°±ç›´æ¥æ‹‹å‡ºï¼Œä¸é‡è©¦
                        raise e
            
            if final_response_text is None:
                raise Exception("Gemini API é‡è©¦å¤šæ¬¡å¾Œä»ç„¶å¤±æ•— (503 Overloaded)ã€‚")
            
            # å›å‚³æœ€çµ‚çš„æ–‡å­—
            return final_response_text
            
    except Exception as e:
        print(f"[AI æµç¨‹]ï¼šåœ¨ä¸»è¦ AI æµç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        return f"AI åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
    
    finally:
        # -------------------------------------------------
        # æ­¥é©Ÿ 7: æ¸…ç†æš«å­˜æª”æ¡ˆ
        # -------------------------------------------------
        if local_temp_video_path and os.path.exists(local_temp_video_path):
            os.remove(local_temp_video_path)
            print(f"[AI æµç¨‹]ï¼šæš«å­˜å½±ç‰‡ {local_temp_video_path} å·²åˆªé™¤ã€‚")